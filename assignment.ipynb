{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/harsh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/harsh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/harsh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(folder, new_folder):\n",
    "    files = os.listdir(folder)\n",
    "    count = 0\n",
    "    for file in files:\n",
    "        path = os.path.join(os.getcwd(), folder, file)\n",
    "        with open(path) as fp:\n",
    "            \n",
    "            soup = BeautifulSoup(fp, 'html.parser')\n",
    "            if count < 5:\n",
    "                print(\"Before Extraction : \", soup)\n",
    "            text = soup.findAll(\"text\")[0].text\n",
    "            title = soup.findAll(\"title\")[0].text\n",
    "            final_text = title + \" \" + text\n",
    "            if count < 5:\n",
    "                print(\"After Extraction : \", final_text)\n",
    "                count += 1\n",
    "            \n",
    "        new_file_path = os.path.join(os.getcwd(), new_folder, file)\n",
    "        with open(new_file_path, \"w\") as fw:\n",
    "            fw.write(final_text)\n",
    "            fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset  already exists.\n",
      "Before Extraction :  <doc>\n",
      "<docno>\n",
      "1223\n",
      "</docno>\n",
      "<title>\n",
      "inviscid-incompressible-flow theory of static two-dimensional\n",
      "solid jets, in proximity to the ground .\n",
      "</title>\n",
      "<author>\n",
      "strand,t.\n",
      "</author>\n",
      "<biblio>\n",
      "j. ae. scs. 1962, 170.\n",
      "</biblio>\n",
      "<text>\n",
      "  the inviscid-incompressible-flow theory of static two-dimensional\n",
      "solid jets impinging orthogonally on the ground is presented\n",
      "using conformal mapping methods .\n",
      "  it is shown that the thrust of a solid jet at constant power\n",
      "initially decreases as the ground is approached .  the magnitude\n",
      "of the thrust out of ground effect is regained only at a very\n",
      "low height-to-jet width ratio (approximately 0.55) .  the maximuin\n",
      "decrease is about 6 percent .  the ground effect on solid\n",
      "jets is thus largely unfavorable .\n",
      "</text>\n",
      "</doc>\n",
      "\n",
      "After Extraction :  \n",
      "inviscid-incompressible-flow theory of static two-dimensional\n",
      "solid jets, in proximity to the ground .\n",
      " \n",
      "  the inviscid-incompressible-flow theory of static two-dimensional\n",
      "solid jets impinging orthogonally on the ground is presented\n",
      "using conformal mapping methods .\n",
      "  it is shown that the thrust of a solid jet at constant power\n",
      "initially decreases as the ground is approached .  the magnitude\n",
      "of the thrust out of ground effect is regained only at a very\n",
      "low height-to-jet width ratio (approximately 0.55) .  the maximuin\n",
      "decrease is about 6 percent .  the ground effect on solid\n",
      "jets is thus largely unfavorable .\n",
      "\n",
      "Before Extraction :  <doc>\n",
      "<docno>\n",
      "1011\n",
      "</docno>\n",
      "<title>\n",
      "free-flight measurements of the static and dynamic\n",
      "</title>\n",
      "<author>\n",
      "</author>\n",
      "<biblio>\n",
      "</biblio>\n",
      "<text>\n",
      "  charts have been prepared relating the thermodynamic properties of\n",
      "air in chemical equilibrium for temperatures to 15,000 k and for pressures\n",
      "from 10 to 10 atmospheres .  also included are charts showing\n",
      "the composition of air, the isentropic exponent, and the speed of\n",
      "sound .  these charts are based on thermodynamic data calculated by the\n",
      "national bureau of standards .\n",
      "</text>\n",
      "</doc>\n",
      "\n",
      "After Extraction :  \n",
      "free-flight measurements of the static and dynamic\n",
      " \n",
      "  charts have been prepared relating the thermodynamic properties of\n",
      "air in chemical equilibrium for temperatures to 15,000 k and for pressures\n",
      "from 10 to 10 atmospheres .  also included are charts showing\n",
      "the composition of air, the isentropic exponent, and the speed of\n",
      "sound .  these charts are based on thermodynamic data calculated by the\n",
      "national bureau of standards .\n",
      "\n",
      "Before Extraction :  <doc>\n",
      "<docno>\n",
      "795\n",
      "</docno>\n",
      "<title>\n",
      "the operation of the npl 18in x 14in. wind tunnel in the transonic speed\n",
      " range .\n",
      "</title>\n",
      "<author>\n",
      "hall, i.m.\n",
      "</author>\n",
      "<biblio>\n",
      "a.r.c. c.p. 338, january 1957 .\n",
      "</biblio>\n",
      "<text>\n",
      "a brief description of the slotted liners used is given together with\n",
      "the power requirements and some flow surveys .\n",
      "some observations are made on wall interference on a half-model of a\n",
      "swept wing tested in the wind tunnel .\n",
      "</text>\n",
      "</doc>\n",
      "\n",
      "After Extraction :  \n",
      "the operation of the npl 18in x 14in. wind tunnel in the transonic speed\n",
      " range .\n",
      " \n",
      "a brief description of the slotted liners used is given together with\n",
      "the power requirements and some flow surveys .\n",
      "some observations are made on wall interference on a half-model of a\n",
      "swept wing tested in the wind tunnel .\n",
      "\n",
      "Before Extraction :  <doc>\n",
      "<docno>\n",
      "553\n",
      "</docno>\n",
      "<title>\n",
      "ablation of glassy materials around blunt bodies of\n",
      "revolution .\n",
      "</title>\n",
      "<author>\n",
      "hidalgo,h.\n",
      "</author>\n",
      "<biblio>\n",
      "ars j. 30, 1960.\n",
      "</biblio>\n",
      "<text>\n",
      "  the steady-state equations of motion for a\n",
      "thin layer of an incompressible glassy material on the\n",
      "surface of an ablating and radiating blunt\n",
      "body are reduced to a first-order ordinary differential\n",
      "equation which is integrated numerically .\n",
      "this solution is coupled with the solution of the air\n",
      "boundary layer for both laminar and turbulent\n",
      "heat transfer with or without mass vaporization of\n",
      "the ablating material .  the distribution of the\n",
      "effective energy of ablation around the body is thus\n",
      "obtained for a cone cylinder with a hemispherical\n",
      "cap that re-enters the atmosphere at hypersonic\n",
      "flight speeds, and has quartz as the ablating\n",
      "material .  it is found that the ablation process from\n",
      "turbulent heating is more efficient than from\n",
      "the laminar case because of increased vaporization .\n",
      "this solution of the equations of motion at the\n",
      "stagnation point has been verified by are wind tunnel\n",
      "experiments .  the present state of development\n",
      "of the are wind tunnel does not permit its use for\n",
      "experimental investigations of ablation around\n",
      "blunt bodies under turbulent heating .\n",
      "</text>\n",
      "</doc>\n",
      "\n",
      "After Extraction :  \n",
      "ablation of glassy materials around blunt bodies of\n",
      "revolution .\n",
      " \n",
      "  the steady-state equations of motion for a\n",
      "thin layer of an incompressible glassy material on the\n",
      "surface of an ablating and radiating blunt\n",
      "body are reduced to a first-order ordinary differential\n",
      "equation which is integrated numerically .\n",
      "this solution is coupled with the solution of the air\n",
      "boundary layer for both laminar and turbulent\n",
      "heat transfer with or without mass vaporization of\n",
      "the ablating material .  the distribution of the\n",
      "effective energy of ablation around the body is thus\n",
      "obtained for a cone cylinder with a hemispherical\n",
      "cap that re-enters the atmosphere at hypersonic\n",
      "flight speeds, and has quartz as the ablating\n",
      "material .  it is found that the ablation process from\n",
      "turbulent heating is more efficient than from\n",
      "the laminar case because of increased vaporization .\n",
      "this solution of the equations of motion at the\n",
      "stagnation point has been verified by are wind tunnel\n",
      "experiments .  the present state of development\n",
      "of the are wind tunnel does not permit its use for\n",
      "experimental investigations of ablation around\n",
      "blunt bodies under turbulent heating .\n",
      "\n",
      "Before Extraction :  <doc>\n",
      "<docno>\n",
      "761\n",
      "</docno>\n",
      "<title>\n",
      "buckling of sandwich under normal pressure .\n",
      "</title>\n",
      "<author>\n",
      "yao,j.c.\n",
      "</author>\n",
      "<biblio>\n",
      "j. ae. scs. 29, 1962, 264.\n",
      "</biblio>\n",
      "<text>\n",
      "  a theoretical study is made of the buckling of a sandwich sphere\n",
      "comprised of a core layer of low-modulus material and two thin\n",
      "facing layers of higher modulus material .  the solution for the\n",
      "buckling resistance of the sphere under normal external pressure\n",
      "is obtained by linearized theory, and is reducible to the classical\n",
      "solution for monocoque spherical shells .  critical buckling pressures\n",
      "are calculated for various radius-thickness ratios and sphere\n",
      "materials .\n",
      "</text>\n",
      "</doc>\n",
      "\n",
      "After Extraction :  \n",
      "buckling of sandwich under normal pressure .\n",
      " \n",
      "  a theoretical study is made of the buckling of a sandwich sphere\n",
      "comprised of a core layer of low-modulus material and two thin\n",
      "facing layers of higher modulus material .  the solution for the\n",
      "buckling resistance of the sphere under normal external pressure\n",
      "is obtained by linearized theory, and is reducible to the classical\n",
      "solution for monocoque spherical shells .  critical buckling pressures\n",
      "are calculated for various radius-thickness ratios and sphere\n",
      "materials .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_folder = 'Dataset'\n",
    "try:\n",
    "    os.mkdir(new_folder)\n",
    "except:\n",
    "    print(new_folder, \" already exists.\")\n",
    "file_map = extract_data('CSE508_Winter2023_Dataset', new_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, flag):\n",
    "    if flag:\n",
    "        print(\"\\033[1m\" + \"Before lower case text : \" + \"\\033[0m\" , text)\n",
    "        \n",
    "    text = text.lower()\n",
    "    if flag:\n",
    "        print(\"\\033[1m\" + \"After lower case text and before tokenization : \"+ \"\\033[0m\", text)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    if flag:\n",
    "        print(\"\\033[1m\" + \"After tokenization and before stopwords removal : \"+ \"\\033[0m\", tokens)\n",
    "    \n",
    "    final = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    if flag:\n",
    "        print(\"\\033[1m\" + \"After stopwords removal and before punctuations removal : \"+ \"\\033[0m\", final)\n",
    "\n",
    "    tokens = [word for word in final if word not in string.punctuation]\n",
    "    \n",
    "    if flag:\n",
    "        print(\"\\033[1m\" + \"After punctuations and before blank space token removal : \"+ \"\\033[0m\", tokens)\n",
    "     \n",
    "    final = [word for word in tokens if len(re.findall(r'\\s+', word)) == 0]\n",
    "    \n",
    "    if flag:\n",
    "        print(\"\\033[1m\" + \"After blank space token removal : \"+ \"\\033[0m\", final)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "Printing Statement : 1\n",
      "\u001b[1mBefore lower case text : \u001b[0m \n",
      "inviscid-incompressible-flow theory of static two-dimensional\n",
      "solid jets, in proximity to the ground .\n",
      " \n",
      "  the inviscid-incompressible-flow theory of static two-dimensional\n",
      "solid jets impinging orthogonally on the ground is presented\n",
      "using conformal mapping methods .\n",
      "  it is shown that the thrust of a solid jet at constant power\n",
      "initially decreases as the ground is approached .  the magnitude\n",
      "of the thrust out of ground effect is regained only at a very\n",
      "low height-to-jet width ratio (approximately 0.55) .  the maximuin\n",
      "decrease is about 6 percent .  the ground effect on solid\n",
      "jets is thus largely unfavorable .\n",
      "\n",
      "\u001b[1mAfter lower case text and before tokenization : \u001b[0m \n",
      "inviscid-incompressible-flow theory of static two-dimensional\n",
      "solid jets, in proximity to the ground .\n",
      " \n",
      "  the inviscid-incompressible-flow theory of static two-dimensional\n",
      "solid jets impinging orthogonally on the ground is presented\n",
      "using conformal mapping methods .\n",
      "  it is shown that the thrust of a solid jet at constant power\n",
      "initially decreases as the ground is approached .  the magnitude\n",
      "of the thrust out of ground effect is regained only at a very\n",
      "low height-to-jet width ratio (approximately 0.55) .  the maximuin\n",
      "decrease is about 6 percent .  the ground effect on solid\n",
      "jets is thus largely unfavorable .\n",
      "\n",
      "\u001b[1mAfter tokenization and before stopwords removal : \u001b[0m ['inviscid-incompressible-flow', 'theory', 'of', 'static', 'two-dimensional', 'solid', 'jets', ',', 'in', 'proximity', 'to', 'the', 'ground', '.', 'the', 'inviscid-incompressible-flow', 'theory', 'of', 'static', 'two-dimensional', 'solid', 'jets', 'impinging', 'orthogonally', 'on', 'the', 'ground', 'is', 'presented', 'using', 'conformal', 'mapping', 'methods', '.', 'it', 'is', 'shown', 'that', 'the', 'thrust', 'of', 'a', 'solid', 'jet', 'at', 'constant', 'power', 'initially', 'decreases', 'as', 'the', 'ground', 'is', 'approached', '.', 'the', 'magnitude', 'of', 'the', 'thrust', 'out', 'of', 'ground', 'effect', 'is', 'regained', 'only', 'at', 'a', 'very', 'low', 'height-to-jet', 'width', 'ratio', '(', 'approximately', '0.55', ')', '.', 'the', 'maximuin', 'decrease', 'is', 'about', '6', 'percent', '.', 'the', 'ground', 'effect', 'on', 'solid', 'jets', 'is', 'thus', 'largely', 'unfavorable', '.']\n",
      "\u001b[1mAfter stopwords removal and before punctuations removal : \u001b[0m ['inviscid-incompressible-flow', 'theory', 'static', 'two-dimensional', 'solid', 'jets', ',', 'proximity', 'ground', '.', 'inviscid-incompressible-flow', 'theory', 'static', 'two-dimensional', 'solid', 'jets', 'impinging', 'orthogonally', 'ground', 'presented', 'using', 'conformal', 'mapping', 'methods', '.', 'shown', 'thrust', 'solid', 'jet', 'constant', 'power', 'initially', 'decreases', 'ground', 'approached', '.', 'magnitude', 'thrust', 'ground', 'effect', 'regained', 'low', 'height-to-jet', 'width', 'ratio', '(', 'approximately', '0.55', ')', '.', 'maximuin', 'decrease', '6', 'percent', '.', 'ground', 'effect', 'solid', 'jets', 'thus', 'largely', 'unfavorable', '.']\n",
      "\u001b[1mAfter punctuations and before blank space token removal : \u001b[0m ['inviscid-incompressible-flow', 'theory', 'static', 'two-dimensional', 'solid', 'jets', 'proximity', 'ground', 'inviscid-incompressible-flow', 'theory', 'static', 'two-dimensional', 'solid', 'jets', 'impinging', 'orthogonally', 'ground', 'presented', 'using', 'conformal', 'mapping', 'methods', 'shown', 'thrust', 'solid', 'jet', 'constant', 'power', 'initially', 'decreases', 'ground', 'approached', 'magnitude', 'thrust', 'ground', 'effect', 'regained', 'low', 'height-to-jet', 'width', 'ratio', 'approximately', '0.55', 'maximuin', 'decrease', '6', 'percent', 'ground', 'effect', 'solid', 'jets', 'thus', 'largely', 'unfavorable']\n",
      "\u001b[1mAfter blank space token removal : \u001b[0m ['inviscid-incompressible-flow', 'theory', 'static', 'two-dimensional', 'solid', 'jets', 'proximity', 'ground', 'inviscid-incompressible-flow', 'theory', 'static', 'two-dimensional', 'solid', 'jets', 'impinging', 'orthogonally', 'ground', 'presented', 'using', 'conformal', 'mapping', 'methods', 'shown', 'thrust', 'solid', 'jet', 'constant', 'power', 'initially', 'decreases', 'ground', 'approached', 'magnitude', 'thrust', 'ground', 'effect', 'regained', 'low', 'height-to-jet', 'width', 'ratio', 'approximately', '0.55', 'maximuin', 'decrease', '6', 'percent', 'ground', 'effect', 'solid', 'jets', 'thus', 'largely', 'unfavorable']\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "Printing Statement : 2\n",
      "\u001b[1mBefore lower case text : \u001b[0m \n",
      "free-flight measurements of the static and dynamic\n",
      " \n",
      "  charts have been prepared relating the thermodynamic properties of\n",
      "air in chemical equilibrium for temperatures to 15,000 k and for pressures\n",
      "from 10 to 10 atmospheres .  also included are charts showing\n",
      "the composition of air, the isentropic exponent, and the speed of\n",
      "sound .  these charts are based on thermodynamic data calculated by the\n",
      "national bureau of standards .\n",
      "\n",
      "\u001b[1mAfter lower case text and before tokenization : \u001b[0m \n",
      "free-flight measurements of the static and dynamic\n",
      " \n",
      "  charts have been prepared relating the thermodynamic properties of\n",
      "air in chemical equilibrium for temperatures to 15,000 k and for pressures\n",
      "from 10 to 10 atmospheres .  also included are charts showing\n",
      "the composition of air, the isentropic exponent, and the speed of\n",
      "sound .  these charts are based on thermodynamic data calculated by the\n",
      "national bureau of standards .\n",
      "\n",
      "\u001b[1mAfter tokenization and before stopwords removal : \u001b[0m ['free-flight', 'measurements', 'of', 'the', 'static', 'and', 'dynamic', 'charts', 'have', 'been', 'prepared', 'relating', 'the', 'thermodynamic', 'properties', 'of', 'air', 'in', 'chemical', 'equilibrium', 'for', 'temperatures', 'to', '15,000', 'k', 'and', 'for', 'pressures', 'from', '10', 'to', '10', 'atmospheres', '.', 'also', 'included', 'are', 'charts', 'showing', 'the', 'composition', 'of', 'air', ',', 'the', 'isentropic', 'exponent', ',', 'and', 'the', 'speed', 'of', 'sound', '.', 'these', 'charts', 'are', 'based', 'on', 'thermodynamic', 'data', 'calculated', 'by', 'the', 'national', 'bureau', 'of', 'standards', '.']\n",
      "\u001b[1mAfter stopwords removal and before punctuations removal : \u001b[0m ['free-flight', 'measurements', 'static', 'dynamic', 'charts', 'prepared', 'relating', 'thermodynamic', 'properties', 'air', 'chemical', 'equilibrium', 'temperatures', '15,000', 'k', 'pressures', '10', '10', 'atmospheres', '.', 'also', 'included', 'charts', 'showing', 'composition', 'air', ',', 'isentropic', 'exponent', ',', 'speed', 'sound', '.', 'charts', 'based', 'thermodynamic', 'data', 'calculated', 'national', 'bureau', 'standards', '.']\n",
      "\u001b[1mAfter punctuations and before blank space token removal : \u001b[0m ['free-flight', 'measurements', 'static', 'dynamic', 'charts', 'prepared', 'relating', 'thermodynamic', 'properties', 'air', 'chemical', 'equilibrium', 'temperatures', '15,000', 'k', 'pressures', '10', '10', 'atmospheres', 'also', 'included', 'charts', 'showing', 'composition', 'air', 'isentropic', 'exponent', 'speed', 'sound', 'charts', 'based', 'thermodynamic', 'data', 'calculated', 'national', 'bureau', 'standards']\n",
      "\u001b[1mAfter blank space token removal : \u001b[0m ['free-flight', 'measurements', 'static', 'dynamic', 'charts', 'prepared', 'relating', 'thermodynamic', 'properties', 'air', 'chemical', 'equilibrium', 'temperatures', '15,000', 'k', 'pressures', '10', '10', 'atmospheres', 'also', 'included', 'charts', 'showing', 'composition', 'air', 'isentropic', 'exponent', 'speed', 'sound', 'charts', 'based', 'thermodynamic', 'data', 'calculated', 'national', 'bureau', 'standards']\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "Printing Statement : 3\n",
      "\u001b[1mBefore lower case text : \u001b[0m \n",
      "the operation of the npl 18in x 14in. wind tunnel in the transonic speed\n",
      " range .\n",
      " \n",
      "a brief description of the slotted liners used is given together with\n",
      "the power requirements and some flow surveys .\n",
      "some observations are made on wall interference on a half-model of a\n",
      "swept wing tested in the wind tunnel .\n",
      "\n",
      "\u001b[1mAfter lower case text and before tokenization : \u001b[0m \n",
      "the operation of the npl 18in x 14in. wind tunnel in the transonic speed\n",
      " range .\n",
      " \n",
      "a brief description of the slotted liners used is given together with\n",
      "the power requirements and some flow surveys .\n",
      "some observations are made on wall interference on a half-model of a\n",
      "swept wing tested in the wind tunnel .\n",
      "\n",
      "\u001b[1mAfter tokenization and before stopwords removal : \u001b[0m ['the', 'operation', 'of', 'the', 'npl', '18in', 'x', '14in', '.', 'wind', 'tunnel', 'in', 'the', 'transonic', 'speed', 'range', '.', 'a', 'brief', 'description', 'of', 'the', 'slotted', 'liners', 'used', 'is', 'given', 'together', 'with', 'the', 'power', 'requirements', 'and', 'some', 'flow', 'surveys', '.', 'some', 'observations', 'are', 'made', 'on', 'wall', 'interference', 'on', 'a', 'half-model', 'of', 'a', 'swept', 'wing', 'tested', 'in', 'the', 'wind', 'tunnel', '.']\n",
      "\u001b[1mAfter stopwords removal and before punctuations removal : \u001b[0m ['operation', 'npl', '18in', 'x', '14in', '.', 'wind', 'tunnel', 'transonic', 'speed', 'range', '.', 'brief', 'description', 'slotted', 'liners', 'used', 'given', 'together', 'power', 'requirements', 'flow', 'surveys', '.', 'observations', 'made', 'wall', 'interference', 'half-model', 'swept', 'wing', 'tested', 'wind', 'tunnel', '.']\n",
      "\u001b[1mAfter punctuations and before blank space token removal : \u001b[0m ['operation', 'npl', '18in', 'x', '14in', 'wind', 'tunnel', 'transonic', 'speed', 'range', 'brief', 'description', 'slotted', 'liners', 'used', 'given', 'together', 'power', 'requirements', 'flow', 'surveys', 'observations', 'made', 'wall', 'interference', 'half-model', 'swept', 'wing', 'tested', 'wind', 'tunnel']\n",
      "\u001b[1mAfter blank space token removal : \u001b[0m ['operation', 'npl', '18in', 'x', '14in', 'wind', 'tunnel', 'transonic', 'speed', 'range', 'brief', 'description', 'slotted', 'liners', 'used', 'given', 'together', 'power', 'requirements', 'flow', 'surveys', 'observations', 'made', 'wall', 'interference', 'half-model', 'swept', 'wing', 'tested', 'wind', 'tunnel']\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "Printing Statement : 4\n",
      "\u001b[1mBefore lower case text : \u001b[0m \n",
      "ablation of glassy materials around blunt bodies of\n",
      "revolution .\n",
      " \n",
      "  the steady-state equations of motion for a\n",
      "thin layer of an incompressible glassy material on the\n",
      "surface of an ablating and radiating blunt\n",
      "body are reduced to a first-order ordinary differential\n",
      "equation which is integrated numerically .\n",
      "this solution is coupled with the solution of the air\n",
      "boundary layer for both laminar and turbulent\n",
      "heat transfer with or without mass vaporization of\n",
      "the ablating material .  the distribution of the\n",
      "effective energy of ablation around the body is thus\n",
      "obtained for a cone cylinder with a hemispherical\n",
      "cap that re-enters the atmosphere at hypersonic\n",
      "flight speeds, and has quartz as the ablating\n",
      "material .  it is found that the ablation process from\n",
      "turbulent heating is more efficient than from\n",
      "the laminar case because of increased vaporization .\n",
      "this solution of the equations of motion at the\n",
      "stagnation point has been verified by are wind tunnel\n",
      "experiments .  the present state of development\n",
      "of the are wind tunnel does not permit its use for\n",
      "experimental investigations of ablation around\n",
      "blunt bodies under turbulent heating .\n",
      "\n",
      "\u001b[1mAfter lower case text and before tokenization : \u001b[0m \n",
      "ablation of glassy materials around blunt bodies of\n",
      "revolution .\n",
      " \n",
      "  the steady-state equations of motion for a\n",
      "thin layer of an incompressible glassy material on the\n",
      "surface of an ablating and radiating blunt\n",
      "body are reduced to a first-order ordinary differential\n",
      "equation which is integrated numerically .\n",
      "this solution is coupled with the solution of the air\n",
      "boundary layer for both laminar and turbulent\n",
      "heat transfer with or without mass vaporization of\n",
      "the ablating material .  the distribution of the\n",
      "effective energy of ablation around the body is thus\n",
      "obtained for a cone cylinder with a hemispherical\n",
      "cap that re-enters the atmosphere at hypersonic\n",
      "flight speeds, and has quartz as the ablating\n",
      "material .  it is found that the ablation process from\n",
      "turbulent heating is more efficient than from\n",
      "the laminar case because of increased vaporization .\n",
      "this solution of the equations of motion at the\n",
      "stagnation point has been verified by are wind tunnel\n",
      "experiments .  the present state of development\n",
      "of the are wind tunnel does not permit its use for\n",
      "experimental investigations of ablation around\n",
      "blunt bodies under turbulent heating .\n",
      "\n",
      "\u001b[1mAfter tokenization and before stopwords removal : \u001b[0m ['ablation', 'of', 'glassy', 'materials', 'around', 'blunt', 'bodies', 'of', 'revolution', '.', 'the', 'steady-state', 'equations', 'of', 'motion', 'for', 'a', 'thin', 'layer', 'of', 'an', 'incompressible', 'glassy', 'material', 'on', 'the', 'surface', 'of', 'an', 'ablating', 'and', 'radiating', 'blunt', 'body', 'are', 'reduced', 'to', 'a', 'first-order', 'ordinary', 'differential', 'equation', 'which', 'is', 'integrated', 'numerically', '.', 'this', 'solution', 'is', 'coupled', 'with', 'the', 'solution', 'of', 'the', 'air', 'boundary', 'layer', 'for', 'both', 'laminar', 'and', 'turbulent', 'heat', 'transfer', 'with', 'or', 'without', 'mass', 'vaporization', 'of', 'the', 'ablating', 'material', '.', 'the', 'distribution', 'of', 'the', 'effective', 'energy', 'of', 'ablation', 'around', 'the', 'body', 'is', 'thus', 'obtained', 'for', 'a', 'cone', 'cylinder', 'with', 'a', 'hemispherical', 'cap', 'that', 're-enters', 'the', 'atmosphere', 'at', 'hypersonic', 'flight', 'speeds', ',', 'and', 'has', 'quartz', 'as', 'the', 'ablating', 'material', '.', 'it', 'is', 'found', 'that', 'the', 'ablation', 'process', 'from', 'turbulent', 'heating', 'is', 'more', 'efficient', 'than', 'from', 'the', 'laminar', 'case', 'because', 'of', 'increased', 'vaporization', '.', 'this', 'solution', 'of', 'the', 'equations', 'of', 'motion', 'at', 'the', 'stagnation', 'point', 'has', 'been', 'verified', 'by', 'are', 'wind', 'tunnel', 'experiments', '.', 'the', 'present', 'state', 'of', 'development', 'of', 'the', 'are', 'wind', 'tunnel', 'does', 'not', 'permit', 'its', 'use', 'for', 'experimental', 'investigations', 'of', 'ablation', 'around', 'blunt', 'bodies', 'under', 'turbulent', 'heating', '.']\n",
      "\u001b[1mAfter stopwords removal and before punctuations removal : \u001b[0m ['ablation', 'glassy', 'materials', 'around', 'blunt', 'bodies', 'revolution', '.', 'steady-state', 'equations', 'motion', 'thin', 'layer', 'incompressible', 'glassy', 'material', 'surface', 'ablating', 'radiating', 'blunt', 'body', 'reduced', 'first-order', 'ordinary', 'differential', 'equation', 'integrated', 'numerically', '.', 'solution', 'coupled', 'solution', 'air', 'boundary', 'layer', 'laminar', 'turbulent', 'heat', 'transfer', 'without', 'mass', 'vaporization', 'ablating', 'material', '.', 'distribution', 'effective', 'energy', 'ablation', 'around', 'body', 'thus', 'obtained', 'cone', 'cylinder', 'hemispherical', 'cap', 're-enters', 'atmosphere', 'hypersonic', 'flight', 'speeds', ',', 'quartz', 'ablating', 'material', '.', 'found', 'ablation', 'process', 'turbulent', 'heating', 'efficient', 'laminar', 'case', 'increased', 'vaporization', '.', 'solution', 'equations', 'motion', 'stagnation', 'point', 'verified', 'wind', 'tunnel', 'experiments', '.', 'present', 'state', 'development', 'wind', 'tunnel', 'permit', 'use', 'experimental', 'investigations', 'ablation', 'around', 'blunt', 'bodies', 'turbulent', 'heating', '.']\n",
      "\u001b[1mAfter punctuations and before blank space token removal : \u001b[0m ['ablation', 'glassy', 'materials', 'around', 'blunt', 'bodies', 'revolution', 'steady-state', 'equations', 'motion', 'thin', 'layer', 'incompressible', 'glassy', 'material', 'surface', 'ablating', 'radiating', 'blunt', 'body', 'reduced', 'first-order', 'ordinary', 'differential', 'equation', 'integrated', 'numerically', 'solution', 'coupled', 'solution', 'air', 'boundary', 'layer', 'laminar', 'turbulent', 'heat', 'transfer', 'without', 'mass', 'vaporization', 'ablating', 'material', 'distribution', 'effective', 'energy', 'ablation', 'around', 'body', 'thus', 'obtained', 'cone', 'cylinder', 'hemispherical', 'cap', 're-enters', 'atmosphere', 'hypersonic', 'flight', 'speeds', 'quartz', 'ablating', 'material', 'found', 'ablation', 'process', 'turbulent', 'heating', 'efficient', 'laminar', 'case', 'increased', 'vaporization', 'solution', 'equations', 'motion', 'stagnation', 'point', 'verified', 'wind', 'tunnel', 'experiments', 'present', 'state', 'development', 'wind', 'tunnel', 'permit', 'use', 'experimental', 'investigations', 'ablation', 'around', 'blunt', 'bodies', 'turbulent', 'heating']\n",
      "\u001b[1mAfter blank space token removal : \u001b[0m ['ablation', 'glassy', 'materials', 'around', 'blunt', 'bodies', 'revolution', 'steady-state', 'equations', 'motion', 'thin', 'layer', 'incompressible', 'glassy', 'material', 'surface', 'ablating', 'radiating', 'blunt', 'body', 'reduced', 'first-order', 'ordinary', 'differential', 'equation', 'integrated', 'numerically', 'solution', 'coupled', 'solution', 'air', 'boundary', 'layer', 'laminar', 'turbulent', 'heat', 'transfer', 'without', 'mass', 'vaporization', 'ablating', 'material', 'distribution', 'effective', 'energy', 'ablation', 'around', 'body', 'thus', 'obtained', 'cone', 'cylinder', 'hemispherical', 'cap', 're-enters', 'atmosphere', 'hypersonic', 'flight', 'speeds', 'quartz', 'ablating', 'material', 'found', 'ablation', 'process', 'turbulent', 'heating', 'efficient', 'laminar', 'case', 'increased', 'vaporization', 'solution', 'equations', 'motion', 'stagnation', 'point', 'verified', 'wind', 'tunnel', 'experiments', 'present', 'state', 'development', 'wind', 'tunnel', 'permit', 'use', 'experimental', 'investigations', 'ablation', 'around', 'blunt', 'bodies', 'turbulent', 'heating']\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n",
      "Printing Statement : 5\n",
      "\u001b[1mBefore lower case text : \u001b[0m \n",
      "buckling of sandwich under normal pressure .\n",
      " \n",
      "  a theoretical study is made of the buckling of a sandwich sphere\n",
      "comprised of a core layer of low-modulus material and two thin\n",
      "facing layers of higher modulus material .  the solution for the\n",
      "buckling resistance of the sphere under normal external pressure\n",
      "is obtained by linearized theory, and is reducible to the classical\n",
      "solution for monocoque spherical shells .  critical buckling pressures\n",
      "are calculated for various radius-thickness ratios and sphere\n",
      "materials .\n",
      "\n",
      "\u001b[1mAfter lower case text and before tokenization : \u001b[0m \n",
      "buckling of sandwich under normal pressure .\n",
      " \n",
      "  a theoretical study is made of the buckling of a sandwich sphere\n",
      "comprised of a core layer of low-modulus material and two thin\n",
      "facing layers of higher modulus material .  the solution for the\n",
      "buckling resistance of the sphere under normal external pressure\n",
      "is obtained by linearized theory, and is reducible to the classical\n",
      "solution for monocoque spherical shells .  critical buckling pressures\n",
      "are calculated for various radius-thickness ratios and sphere\n",
      "materials .\n",
      "\n",
      "\u001b[1mAfter tokenization and before stopwords removal : \u001b[0m ['buckling', 'of', 'sandwich', 'under', 'normal', 'pressure', '.', 'a', 'theoretical', 'study', 'is', 'made', 'of', 'the', 'buckling', 'of', 'a', 'sandwich', 'sphere', 'comprised', 'of', 'a', 'core', 'layer', 'of', 'low-modulus', 'material', 'and', 'two', 'thin', 'facing', 'layers', 'of', 'higher', 'modulus', 'material', '.', 'the', 'solution', 'for', 'the', 'buckling', 'resistance', 'of', 'the', 'sphere', 'under', 'normal', 'external', 'pressure', 'is', 'obtained', 'by', 'linearized', 'theory', ',', 'and', 'is', 'reducible', 'to', 'the', 'classical', 'solution', 'for', 'monocoque', 'spherical', 'shells', '.', 'critical', 'buckling', 'pressures', 'are', 'calculated', 'for', 'various', 'radius-thickness', 'ratios', 'and', 'sphere', 'materials', '.']\n",
      "\u001b[1mAfter stopwords removal and before punctuations removal : \u001b[0m ['buckling', 'sandwich', 'normal', 'pressure', '.', 'theoretical', 'study', 'made', 'buckling', 'sandwich', 'sphere', 'comprised', 'core', 'layer', 'low-modulus', 'material', 'two', 'thin', 'facing', 'layers', 'higher', 'modulus', 'material', '.', 'solution', 'buckling', 'resistance', 'sphere', 'normal', 'external', 'pressure', 'obtained', 'linearized', 'theory', ',', 'reducible', 'classical', 'solution', 'monocoque', 'spherical', 'shells', '.', 'critical', 'buckling', 'pressures', 'calculated', 'various', 'radius-thickness', 'ratios', 'sphere', 'materials', '.']\n",
      "\u001b[1mAfter punctuations and before blank space token removal : \u001b[0m ['buckling', 'sandwich', 'normal', 'pressure', 'theoretical', 'study', 'made', 'buckling', 'sandwich', 'sphere', 'comprised', 'core', 'layer', 'low-modulus', 'material', 'two', 'thin', 'facing', 'layers', 'higher', 'modulus', 'material', 'solution', 'buckling', 'resistance', 'sphere', 'normal', 'external', 'pressure', 'obtained', 'linearized', 'theory', 'reducible', 'classical', 'solution', 'monocoque', 'spherical', 'shells', 'critical', 'buckling', 'pressures', 'calculated', 'various', 'radius-thickness', 'ratios', 'sphere', 'materials']\n",
      "\u001b[1mAfter blank space token removal : \u001b[0m ['buckling', 'sandwich', 'normal', 'pressure', 'theoretical', 'study', 'made', 'buckling', 'sandwich', 'sphere', 'comprised', 'core', 'layer', 'low-modulus', 'material', 'two', 'thin', 'facing', 'layers', 'higher', 'modulus', 'material', 'solution', 'buckling', 'resistance', 'sphere', 'normal', 'external', 'pressure', 'obtained', 'linearized', 'theory', 'reducible', 'classical', 'solution', 'monocoque', 'spherical', 'shells', 'critical', 'buckling', 'pressures', 'calculated', 'various', 'radius-thickness', 'ratios', 'sphere', 'materials']\n",
      "**********************************************************************************************\n",
      "**********************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "L = []\n",
    "idtoName = {}\n",
    "files = os.listdir(\"Dataset\")\n",
    "count = 0\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    idtoName[i] = file\n",
    "    path = os.path.join(os.getcwd(), \"Dataset\", file)\n",
    "    \n",
    "    with open(path) as fp:\n",
    "        text = fp.read()\n",
    "        if count < 5:\n",
    "            print(\"**********************************************************************************************\")\n",
    "            print(\"**********************************************************************************************\")\n",
    "            print(f\"Printing Statement : {count+1}\")\n",
    "            L.append(preprocess(text, True))\n",
    "            print(\"**********************************************************************************************\")\n",
    "            print(\"**********************************************************************************************\")\n",
    "            count += 1\n",
    "        else:\n",
    "            L.append(preprocess(text, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Boolean Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_inverted_index(doc_list):\n",
    "    uni_inv_idx = {}\n",
    "    for doc_id, tokens in enumerate(doc_list):\n",
    "        for idx, token in enumerate(tokens):\n",
    "            if token in uni_inv_idx:\n",
    "                if doc_id not in uni_inv_idx[token]:\n",
    "                    uni_inv_idx[token].append(doc_id)\n",
    "            else:\n",
    "                uni_inv_idx[token] = [doc_id]\n",
    "\n",
    "    return uni_inv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_inv_idx = unigram_inverted_index(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Saving to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filehandler = open(\"uni_inv_idx.obj\",\"wb\")\n",
    "pickle.dump(uni_inv_idx, filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading from Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"uni_inv_idx.obj\",'rb')\n",
    "uni_inv_idx = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def andQuery(L1, L2):\n",
    "    ans = []\n",
    "    comparison = 0\n",
    "    len1, len2 = len(L1), len(L2)\n",
    "    \n",
    "    i , j = 0, 0\n",
    "    while i < len1 and j < len2:\n",
    "        if L1[i] == L2[j]:\n",
    "            ans.append(L1[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i] < L2[j]:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "        comparison += 1\n",
    "    \n",
    "    return ans, comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def andNotQuery(L1, L2):\n",
    "    _L2 = [i for i in range(1400) if i not in L2]   \n",
    "    return andQuery(L1, _L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orQuery(L1, L2):\n",
    "    ans = []\n",
    "    comparison = 0\n",
    "    len1, len2 = len(L1), len(L2)\n",
    "    \n",
    "    i , j = 0, 0\n",
    "    while i < len1 and j < len2:\n",
    "        if L1[i] == L2[j]:\n",
    "            ans.append(L1[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i] < L2[j]:\n",
    "            ans.append(L1[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            ans.append(L2[j])\n",
    "            j += 1\n",
    "            \n",
    "        comparison += 1\n",
    "    \n",
    "    while i < len1:\n",
    "        ans.append(L1[i])\n",
    "        i += 1\n",
    "    \n",
    "    while j < len2:\n",
    "        ans.append(L2[j])\n",
    "        j += 1\n",
    "\n",
    "    return ans, comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orNotQuery(L1, L2):\n",
    "    _L2 = [i for i in range(1400) if i not in L2]   \n",
    "    return orQuery(L1, _L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(i, query, operator, comparisons):\n",
    "    if i == len(operator):\n",
    "        return query, comparisons\n",
    "    \n",
    "    res = []\n",
    "    comp = 0\n",
    "\n",
    "    if 'OR' in operator[i] and 'NOT' not in operator[i]:\n",
    "        # print('OR')\n",
    "        res, comp = orQuery(query[0], query[1])\n",
    "\n",
    "    if 'AND' in operator[i] and 'NOT' not in operator[i]:\n",
    "        # print('AND')\n",
    "        res, comp = andQuery(query[0], query[1])\n",
    "\n",
    "    if 'AND NOT' in operator[i]:\n",
    "        # print('AND NOT')\n",
    "        res, comp = andNotQuery(query[0], query[1])\n",
    "    \n",
    "    if 'OR NOT' in operator[i]:\n",
    "        # print('OR NOT')\n",
    "        res, comp = orNotQuery(query[0], query[1])\n",
    "    \n",
    "    del query[ : 2]\n",
    "    query.insert(0, res)\n",
    "    comparisons += comp\n",
    "    \n",
    "    return process_query(i + 1, query, operator, comparisons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram query input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_queries(queries, operand, uni_inv_idx):\n",
    "    queries_expression, no_of_docs, doc_names, no_of_comp = list(), list(), list(), list()\n",
    "    for idx in range(len(queries)):\n",
    "        op = operand[idx]\n",
    "        ip1 = queries[idx]\n",
    "        op = op.split(',')\n",
    "        ip1 = preprocess(ip1, False)\n",
    "        query = [uni_inv_idx[i] if i in uni_inv_idx else [] for i in ip1]\n",
    "\n",
    "        if len(query) != len(op) + 1:\n",
    "            queries_expression.append(\"Inappropriate query !!!. Input Mismatch\")\n",
    "            no_of_docs.append(-1)\n",
    "            doc_names.append(list())\n",
    "            no_of_comp.append(-1)\n",
    "            continue\n",
    "\n",
    "        sent = \"\"\n",
    "        p, q = 0, 0\n",
    "        for idx in range(len(query) + len(op)):\n",
    "            if idx % 2 == 0:\n",
    "                sent += ip1[p] + \" \"\n",
    "                p += 1\n",
    "            else:\n",
    "                sent += op[q] + \" \"\n",
    "                q += 1\n",
    "\n",
    "        comparisons = 0\n",
    "        output, comparisons = process_query(0, query, op, comparisons)\n",
    "        docs = [idtoName[i] for i in output[0]]\n",
    "        queries_expression.append(sent)\n",
    "        no_of_docs.append(len(output[0]))\n",
    "        doc_names.append(docs)\n",
    "        no_of_comp.append(comparisons)\n",
    "    \n",
    "    return queries_expression, no_of_docs, doc_names, no_of_comp\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of queries.2\n",
      "Query : cylinders dress flower\n",
      "Operand : AND,AND NOT\n",
      "Query : phrase queries\n",
      "Operand : AND\n",
      "Query 1:  cylinders AND dress AND NOT flower \n",
      "Number of documents retrieved for query 1:  0\n",
      "Names of the documents retrieved for query 1:  []\n",
      "Number of comparisons required for query 1:  0\n",
      "Query 2:  phrase AND queries \n",
      "Number of documents retrieved for query 2:  0\n",
      "Names of the documents retrieved for query 2:  []\n",
      "Number of comparisons required for query 2:  0\n"
     ]
    }
   ],
   "source": [
    "N = int(input(\"Enter the number of queries.\"))\n",
    "count = 1\n",
    "queries = []\n",
    "operand = []\n",
    "while count <= N:\n",
    "    query = input(\"Query : \")\n",
    "    oper = input(\"Operand : \")\n",
    "    queries.append(query)\n",
    "    operand.append(oper)\n",
    "    count +=1\n",
    "\n",
    "queries_expression, no_of_docs, doc_names, no_of_comp = unigram_queries(queries, operand, uni_inv_idx)\n",
    "for idx in range(len(queries)):\n",
    "    print(f\"Query {idx + 1}: \", queries_expression[idx])\n",
    "    print(f\"Number of documents retrieved for query {idx + 1}: \", no_of_docs[idx])\n",
    "    print(f\"Names of the documents retrieved for query {idx + 1}: \", doc_names[idx])\n",
    "    print(f\"Number of comparisons required for query {idx + 1}: \", no_of_comp[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Phrase Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_inverted_index(L, files):\n",
    "    bi_inv_idx = {}\n",
    "    for doc_id, tokens in enumerate(L):\n",
    "        for idx, _ in enumerate(tokens):\n",
    "#             print(tokens[idx])\n",
    "            if idx <= len(tokens) - 2:\n",
    "                bigram_word = tokens[idx] + \" \" + tokens[idx + 1]\n",
    "                if bigram_word not in bi_inv_idx:\n",
    "                    bi_inv_idx[bigram_word] = list()\n",
    "                    bi_inv_idx[bigram_word].append(doc_id)\n",
    "                else:\n",
    "                    if doc_id not in bi_inv_idx[bigram_word]:\n",
    "                        bi_inv_idx[bigram_word].append(doc_id)\n",
    "                    \n",
    "    return bi_inv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_inv_idx = bigram_inverted_index(L, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open(\"bi_inv_idx.obj\",\"wb\")\n",
    "pickle.dump(bi_inv_idx, filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"bi_inv_idx.obj\",'rb')\n",
    "bi_inv_idx = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_queries(queries, bi_inv_idx):\n",
    "    no_of_docs = []\n",
    "    doc_names = []\n",
    "    for query in queries:\n",
    "        query = preprocess(query, False)\n",
    "#         print(query)\n",
    "        bigram_words  = []\n",
    "        for idx in range(len(query)):\n",
    "            if idx <= len(query) - 2:\n",
    "                bigram_words.append(query[idx] + \" \" + query[idx + 1])\n",
    "#         print(bigram_words)\n",
    "        operand = []  \n",
    "        for idx in range(len(bigram_words) - 1):\n",
    "            operand.append('AND')\n",
    "\n",
    "#         print(operand)\n",
    "        query_doc_list = [bi_inv_idx[i] if i in bi_inv_idx else [] for i in bigram_words]\n",
    "#         print(query_doc_list)\n",
    "        \n",
    "        comparisons = 0\n",
    "        output, _ = process_query(0, query_doc_list, operand, comparisons)\n",
    "        docs = [idtoName[i] for i in output[0]]\n",
    "        no_of_docs.append(len(output[0]))\n",
    "        doc_names.append(docs)\n",
    "        \n",
    "    return no_of_docs, doc_names\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Positional Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_index(doc_list):\n",
    "    pos_idx = {}\n",
    "    for doc_id, tokens in enumerate(doc_list):\n",
    "        for idx, token in enumerate(tokens):\n",
    "            if token in pos_idx:\n",
    "                if doc_id not in pos_idx[token]:\n",
    "                    pos_idx[token][doc_id] = []\n",
    "                    pos_idx[token][doc_id].append(idx)\n",
    "                else:\n",
    "                    pos_idx[token][doc_id].append(idx)\n",
    "            else:\n",
    "                pos_idx[token] = {}\n",
    "                pos_idx[token][doc_id] = []\n",
    "                pos_idx[token][doc_id].append(idx)\n",
    "    return pos_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = positional_index(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open(\"pos_idx.obj\",\"wb\")\n",
    "pickle.dump(pos_index, filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"pos_idx.obj\",'rb')\n",
    "pos_index = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrasal_queries(queries,pos_index,file_map):\n",
    "    phrasal_doc_name = []\n",
    "    phrasal_doc_len = []\n",
    "\n",
    "    for query in queries:\n",
    "        try:\n",
    "            doc_name = []\n",
    "            txt = preprocess(query, False)\n",
    "            if len(txt)==0:\n",
    "                continue\n",
    "\n",
    "            elif len(txt) == 1:\n",
    "                for doc in pos_index[txt[0]]:\n",
    "                    doc_name.append(file_map[doc])\n",
    "\n",
    "            else:\n",
    "                for doc_id in pos_index[txt[0]].keys():\n",
    "                    for pos in pos_index[txt[0]][doc_id]:\n",
    "                        flag = True\n",
    "                        for i in range(1, len(txt)):\n",
    "                            if doc_id not in pos_index[txt[i]] or (pos + i) not in pos_index[txt[i]][doc_id]:\n",
    "                                flag = False\n",
    "                                break\n",
    "                        if flag:\n",
    "                            doc_name.append(file_map[doc_id])\n",
    "            phrasal_doc_name.append(doc_name)\n",
    "            phrasal_doc_len.append(len(doc_name))\n",
    "        except:\n",
    "            phrasal_doc_name.append([])\n",
    "            phrasal_doc_len.append(0)\n",
    "\n",
    "    return phrasal_doc_len, phrasal_doc_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Query Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of queries.4\n",
      "Query : cat bag canister\n",
      "Query : He came back from bigram inverted index\n",
      "Query : omprehensive review of failure\n",
      "Query : comprehensive review of failure\n",
      "Number of documents retrieved for query 1 using bigram inverted index:  0\n",
      "Names of documents retrieved for query  1 using bigram inverted index:  []\n",
      "Number of documents retrieved for query 1 using positional index:  0\n",
      "Names of documents retrieved for query  1 using positional index:  []\n",
      "Number of documents retrieved for query 2 using bigram inverted index:  0\n",
      "Names of documents retrieved for query  2 using bigram inverted index:  []\n",
      "Number of documents retrieved for query 2 using positional index:  0\n",
      "Names of documents retrieved for query  2 using positional index:  []\n",
      "Number of documents retrieved for query 3 using bigram inverted index:  0\n",
      "Names of documents retrieved for query  3 using bigram inverted index:  []\n",
      "Number of documents retrieved for query 3 using positional index:  0\n",
      "Names of documents retrieved for query  3 using positional index:  []\n",
      "Number of documents retrieved for query 4 using bigram inverted index:  1\n",
      "Names of documents retrieved for query  4 using bigram inverted index:  ['cranfield1130']\n",
      "Number of documents retrieved for query 4 using positional index:  1\n",
      "Names of documents retrieved for query  4 using positional index:  ['cranfield1130']\n"
     ]
    }
   ],
   "source": [
    "N = int(input(\"Enter the number of queries.\"))\n",
    "count = 1\n",
    "queries = []\n",
    "while count <= N:\n",
    "    query = input(\"Query : \")\n",
    "    queries.append(query)\n",
    "    count +=1\n",
    "\n",
    "no_of_docs, doc_names = bigram_queries(queries, bi_inv_idx)\n",
    "phrasal_len, phrasal_names = phrasal_queries(queries, pos_index, idtoName)\n",
    "for idx in range(len(queries)):\n",
    "    print(f\"Number of documents retrieved for query {idx + 1} using bigram inverted index: \", no_of_docs[idx])\n",
    "    print(f\"Names of documents retrieved for query  {idx + 1} using bigram inverted index: \", doc_names[idx])\n",
    "    print(f\"Number of documents retrieved for query {idx + 1} using positional index: \", phrasal_len[idx])\n",
    "    print(f\"Names of documents retrieved for query  {idx + 1} using positional index: \", phrasal_names[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3ec7de9268a0b79728a60b875e56ac0966e701affb38f43c868f58afb5023e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
